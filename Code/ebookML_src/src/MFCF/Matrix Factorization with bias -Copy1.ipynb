{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse \n",
    "\n",
    "class MF(object):\n",
    "    def __init__(self, Y, K, lam = 0.1, Xinit = None, Winit = None, \n",
    "                 learning_rate = 0.5, max_iter = 1000, print_every = 100):\n",
    "        self.Y      = Y    # represents the utility matrix \n",
    "        self.K      = K    # \n",
    "        self.lam    = lam  # regularization parameter \n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter      = max_iter # maximum number of iterations \n",
    "        self.print_every   = print_every # print loss+ RMSE on training data after each ? iters \n",
    "        self.n_users       = int(np.max(Y[:, 0])) + 1 \n",
    "        self.n_items       = int(np.max(Y[:, 1])) + 1\n",
    "        self.n_ratings     = Y.shape[0] # number of known ratings\n",
    "        self.X = np.random.randn(self.n_items, K) if Xinit is None else Xinit \n",
    "        self.W = np.random.randn(K, self.n_users) if Winit is None else Winit \n",
    "        self.b = np.random.randn(self.n_items) # item biases\n",
    "        self.d = np.random.randn(self.n_users) # user biases\n",
    "\n",
    "    def loss(self):\n",
    "        L = 0 \n",
    "        for i in range(self.n_ratings):\n",
    "            # user_id, item_id, rating\n",
    "            n, m, rating = int(self.Y[i, 0]), int(self.Y[i, 1]), self.Y[i, 2]\n",
    "            L += 0.5*(self.X[m].dot(self.W[:, n]) + self.b[m] + self.d[n] - rating)**2    \n",
    "        \n",
    "        L /= self.n_ratings\n",
    "        # regularization, don't ever forget this \n",
    "        L += 0.5*self.lam*(np.sum(self.X**2) + np.sum(self.W**2))\n",
    "        return L \n",
    "\n",
    "    def updateXb(self):\n",
    "        for m in range(self.n_items):\n",
    "            # get all users who rated item m and get the corresponding ratings\n",
    "            ids = np.where(self.Y[:, 1] == m)[0] # row indices of items m \n",
    "            user_ids, ratings = self.Y[ids, 0].astype(np.int32), self.Y[ids, 2]\n",
    "            Wm, dm = self.W[:, user_ids], self.d[user_ids]\n",
    "            for i in range(30):\n",
    "                xm = self.X[m]\n",
    "                error = xm.dot(Wm) + self.b[m] + dm  - ratings \n",
    "                grad_xm = error.dot(Wm.T)/self.n_ratings + self.lam*xm\n",
    "                grad_bm = np.sum(error)/self.n_ratings\n",
    "                # gradient descent\n",
    "                self.X[m] -= self.learning_rate*grad_xm.reshape(-1)\n",
    "                self.b[m] -= self.learning_rate*grad_bm\n",
    "    \n",
    "    def updateWd(self): # and d \n",
    "        for n in range(self.n_users):\n",
    "            # get all items rated by user n, and the corresponding ratings\n",
    "            ids = np.where(self.Y[:,0] == n)[0] # row indices of items rated by user n \n",
    "            item_ids, ratings = self.Y[ids, 1].astype(np.int32), self.Y[ids, 2]\n",
    "            Xn, bn = self.X[item_ids], self.b[item_ids]\n",
    "            for i in range(30):\n",
    "                wn = self.W[:, n]\n",
    "                error = Xn.dot(wn) + bn + self.d[n] - ratings\n",
    "                grad_wn = Xn.T.dot(error)/self.n_ratings + self.lam*wn\n",
    "                grad_dn = np.sum(error)/self.n_ratings\n",
    "                # gradient descent\n",
    "                self.W[:, n] -= self.learning_rate*grad_wn.reshape(-1)\n",
    "                self.d[n]    -= self.learning_rate*grad_dn\n",
    "    \n",
    "    def fit(self):\n",
    "        for it in range(self.max_iter):\n",
    "            self.updateWd()\n",
    "            self.updateXb()\n",
    "            if (it + 1) % self.print_every == 0:\n",
    "                rmse_train = self.evaluate_RMSE(self.Y)\n",
    "                print('iter = %d, loss = %.4f, RMSE train = %.4f'%(it + 1, self.loss(), rmse_train))\n",
    "    \n",
    "    def pred(self, u, i):\n",
    "        \"\"\" \n",
    "        predict the rating of user u for item i \n",
    "        \"\"\"\n",
    "        u, i = int(u), int(i)\n",
    "        pred = self.X[i, :].dot(self.W[:, u]) + self.b[i] + self.d[u]# + bias\n",
    "        return max(0, min(5, pred)) # pred should be between 0 and 5 in MoviesLen \n",
    "    \n",
    "    def evaluate_RMSE(self, rate_test):\n",
    "        n_tests = rate_test.shape[0] # number of test \n",
    "        SE = 0 # squared error\n",
    "        for n in range(n_tests):\n",
    "            pred = self.pred(rate_test[n, 0], rate_test[n, 1])\n",
    "            SE += (pred - rate_test[n, 2])**2 \n",
    "\n",
    "        RMSE = np.sqrt(SE/n_tests)\n",
    "        return RMSE\n",
    "        \n",
    "# r_cols = ['user_id', 'item_id', 'rating']\n",
    "# ratings = pd.read_csv('ex.dat', sep = ' ', names = r_cols, encoding='latin-1')\n",
    "# Y_data = ratings.as_matrix()\n",
    "\n",
    "# rs = MF(Y_data, K = 3, max_iter = 1000, print_every = 100, lam = 0.1)\n",
    "# rs.fit()\n",
    "# rs.pred(6, 1)\n",
    "# print(rs.evaluate_RMSE(Y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Áp dụng lên MovieLens 100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols)\n",
    "ratings_test = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols)\n",
    "\n",
    "rate_train = ratings_base.as_matrix()\n",
    "rate_test = ratings_test.as_matrix()\n",
    "\n",
    "# indices start from 0\n",
    "rate_train[:, :2] -= 1\n",
    "rate_test[:, :2] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 5, loss = 0.4447, RMSE train = 0.9429\n",
      "iter = 10, loss = 0.4215, RMSE train = 0.9180\n",
      "iter = 15, loss = 0.4174, RMSE train = 0.9135\n",
      "iter = 20, loss = 0.4161, RMSE train = 0.9120\n",
      "iter = 25, loss = 0.4155, RMSE train = 0.9114\n",
      "iter = 30, loss = 0.4152, RMSE train = 0.9110\n",
      "\n",
      "Matrix Factorization CF, RMSE = 0.9621\n"
     ]
    }
   ],
   "source": [
    "rs = MF(rate_train, K = 50, lam = .01, print_every = 5, learning_rate = 50, max_iter = 30)\n",
    "rs.fit()\n",
    "# evaluate on test data\n",
    "RMSE = rs.evaluate_RMSE(rate_test)\n",
    "print('\\nMatrix Factorization CF, RMSE = %.4f' %RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.X.shape\n",
    "rs.n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
