{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import random\n",
    "from skimage import io, transform\n",
    "import cv2\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "Sky = [128,128,128]\n",
    "Building = [128,0,0]\n",
    "Pole = [192,192,128]\n",
    "Road = [128,64,128]\n",
    "Pavement = [60,40,222]\n",
    "Tree = [128,128,0]\n",
    "SignSymbol = [192,128,128]\n",
    "Fence = [64,64,128]\n",
    "Car = [64,0,128]\n",
    "Pedestrian = [64,64,0]\n",
    "Bicyclist = [0,128,192]\n",
    "Unlabelled = [0,0,0]\n",
    "\n",
    "COLOR_DICT = np.array([Sky, Building, Pole, Road, Pavement,\n",
    "                          Tree, SignSymbol, Fence, Car, Pedestrian, Bicyclist, Unlabelled])\n",
    "\n",
    "\n",
    "def adjustData(img,mask,flag_multi_class,num_class):\n",
    "    if(flag_multi_class):\n",
    "        img = img / 255\n",
    "        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
    "        new_mask = np.zeros(mask.shape + (num_class,))\n",
    "        for i in range(num_class):\n",
    "            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
    "            #index = np.where(mask == i)\n",
    "            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
    "            #new_mask[index_mask] = 1\n",
    "            new_mask[mask == i,i] = 1\n",
    "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
    "        mask = new_mask\n",
    "    elif(np.max(img) > 1):\n",
    "        img = img / 255\n",
    "        mask = mask /255\n",
    "        mask[mask > 0.5] = 1\n",
    "        mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "\n",
    "\n",
    "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
    "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
    "        yield (img,mask)\n",
    "\n",
    "\n",
    "\n",
    "def testGenerator_backup(test_path,num_image = 30,target_size = (256,256),flag_multi_class = False,as_gray = True):\n",
    "    for i in range(num_image):\n",
    "        img = io.imread(os.path.join(test_path, \"%d.jpg\" % i), as_gray=as_gray)\n",
    "        img = img / 255\n",
    "        img = trans.resize(img,target_size)\n",
    "        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
    "        img = np.reshape(img,(1,)+img.shape)\n",
    "        yield img\n",
    "\n",
    "def testGenerator(test_path, save_path, num_image, target_size, image_save_prefix):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    image_files = [f for f in os.listdir(test_path) if os.path.isfile(os.path.join(test_path, f))]\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Fliplr(0.5),                \n",
    "        iaa.Affine(rotate=(-20, 20)),   \n",
    "        iaa.Multiply((0.5, 1.5)),       \n",
    "        iaa.GaussianBlur(sigma=(0, 1.0))\n",
    "    ])\n",
    "\n",
    "    for i in range(num_image):\n",
    "        random_image_path = os.path.join(test_path, random.choice(image_files))\n",
    "        img = cv2.imread(random_image_path)\n",
    "        img_resized = cv2.resize(img, target_size)\n",
    "        img_augmented = seq(images=[img_resized])[0]\n",
    "        new_image_name = f\"{image_save_prefix}.{i}.{random.randint(0, 10000)}.jpg\"\n",
    "        cv2.imwrite(os.path.join(save_path, new_image_name), img_augmented)\n",
    "        # print(f\"Saved image: {new_image_name}\")\n",
    "\n",
    "def geneTrainNpy(image_path,mask_path,flag_multi_class = False,num_class = 2,image_prefix = \"image\",mask_prefix = \"mask\",image_as_gray = True,mask_as_gray = True):\n",
    "    image_name_arr = glob.glob(os.path.join(image_path,\"%s*.jpg\"%image_prefix))\n",
    "    image_arr = []\n",
    "    mask_arr = []\n",
    "    for index,item in enumerate(image_name_arr):\n",
    "        img = io.imread(item,as_gray = image_as_gray)\n",
    "        img = np.reshape(img,img.shape + (1,)) if image_as_gray else img\n",
    "        mask = io.imread(item.replace(image_path,mask_path).replace(image_prefix,mask_prefix),as_gray = mask_as_gray)\n",
    "        mask = np.reshape(mask,mask.shape + (1,)) if mask_as_gray else mask\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
    "        image_arr.append(img)\n",
    "        mask_arr.append(mask)\n",
    "    image_arr = np.array(image_arr)\n",
    "    mask_arr = np.array(mask_arr)\n",
    "    return image_arr,mask_arr\n",
    "\n",
    "\n",
    "def labelVisualize(num_class,color_dict,img):\n",
    "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
    "    img_out = np.zeros(img.shape + (3,))\n",
    "    for i in range(num_class):\n",
    "        img_out[img == i,:] = color_dict[i]\n",
    "    return img_out / 255\n",
    "\n",
    "\n",
    "\n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"%d_predict.jpg\"%i),img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data augmentation \n",
    "\n",
    "In deep learning tasks, a lot of data is need to train DNN model, when the dataset is not big enough, data augmentation should be applied.\n",
    "\n",
    "keras.preprocessing.image.ImageDataGenerator is a data generator, which can feed the DNN with data like : (data,label), it can also do data augmentation at the same time.\n",
    "\n",
    "It is very convenient for us to use keras.preprocessing.image.ImageDataGenerator to do data augmentation by implement image rotation, shift, rescale and so on... see [keras documentation](https://keras.io/preprocessing/image/) for detail.\n",
    "\n",
    "For image segmentation tasks, the image and mask must be transformed **together!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define your data generator\n",
    "\n",
    "If you want to visualize your data augmentation result, set save_to_dir = your path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```Train , Val``` - Data Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cấu trúc folder chứa dữ liệu train như sau \n",
    "+ data \n",
    "    + train\n",
    "        + cat <== label \n",
    "        + dog \n",
    "            + dog.01.jpg\n",
    "            + ...\n",
    "        + ... \n",
    "    + test \n",
    "    + val   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bluebell', 'Buttercup']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = 'data/train'\n",
    "# Lấy danh sách tất cả các tên thư mục (nhãn)\n",
    "label_folders = [folder_name for folder_name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, folder_name))]\n",
    "label_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you don't want to do data augmentation, set data_gen_args as an empty dict.\n",
    "#data_gen_args = dict()\n",
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize your data augmentation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56 images belonging to 1 classes.\n",
      "Found 0 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56 images belonging to 1 classes.\n",
      "Found 0 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "for label_folder in label_folders:\n",
    "    save_to_dir = \"data_augmentation/train/\" + label_folder\n",
    "    os.makedirs(save_to_dir, exist_ok=True)\n",
    "    myGenerator = trainGenerator(20,'data/train',label_folder,\n",
    "                                'label',data_gen_args,\n",
    "                                image_save_prefix=label_folder,\n",
    "                                mask_save_prefix=label_folder,\n",
    "                                save_to_dir = save_to_dir)\n",
    "\n",
    "    num_batch = 3\n",
    "    for i,batch in enumerate(myGenerator):\n",
    "        if(i >= num_batch):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create .npy data\n",
    "\n",
    "If your computer has enough memory, you can create npy files containing all your images and masks, and feed your DNN with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arr,mask_arr = geneTrainNpy(\"data/membrane/train/aug/\",\"data/membrane/train/aug/\")\n",
    "#np.save(\"data/image_arr.npy\",image_arr)\n",
    "#np.save(\"data/mask_arr.npy\",mask_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ```Test``` - Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'data/test/'\n",
    "label_folders = [folder_name for folder_name in os.listdir(test_path) if os.path.isdir(os.path.join(test_path, folder_name))]\n",
    "# label_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_folder in label_folders:\n",
    "    test_path2 = test_path + \"/\" + label_folder\n",
    "    save_path = \"data_augmentation/test/\" + label_folder\n",
    "    num_image = 10\n",
    "    target_size = (224, 224)\n",
    "    image_save_prefix = label_folder\n",
    "    testGenerator(test_path2, save_path, num_image, target_size, image_save_prefix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
