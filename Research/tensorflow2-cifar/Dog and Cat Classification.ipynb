{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs and Cats Classification\n",
    "Overview : https://www.kaggle.com/competitions/dogs-vs-cats/overview <br>\n",
    "Dataset : https://www.kaggle.com/competitions/dogs-vs-cats/data <br>\n",
    "Tham kháº£o : https://www.kaggle.com/competitions/dogs-vs-cats/code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.src.engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     15\u001b[0m parser \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mArgumentParser(description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensorFlow2.0 CIFAR-10 Training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Downloads\\DeepLearning\\Research\\tensorflow2-cifar\\models\\__init__.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdensenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreact_resnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmobilenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmobilenetv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\Downloads\\DeepLearning\\Research\\tensorflow2-cifar\\models\\senet.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSELayer\u001b[39;00m(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel):\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\__init__.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m _check_tf_version()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Local project imports\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callbacks\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\activations\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Additional activation functions.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgelu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gelu\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhardshrink\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hardshrink\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlisht\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lisht\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\activations\\gelu.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorLike\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mregister_keras_serializable(package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddons\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgelu\u001b[39m(x: TensorLike, approximate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gaussian Error Linear Unit.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    Computes gaussian error linear:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m        A `Tensor`. Has the same type as `x`.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\utils\\types.py:29\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# TODO: Remove once https://github.com/tensorflow/tensorflow/issues/44613 is resolved\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Version(tf\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mrelease \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.13\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrelease:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# New versions of Keras require importing from `keras.src` when\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# importing internal symbols.\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m Version(tf\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mrelease \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrelease:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.src.engine'"
     ]
    }
   ],
   "source": [
    "\"\"\"Train CIFAR-10 with TensorFlow2.0.\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import *\n",
    "from utils import *\n",
    "\n",
    "parser = argparse.ArgumentParser(description='TensorFlow2.0 CIFAR-10 Training')\n",
    "parser.add_argument('--model', required=True, type=str, help='model type')\n",
    "parser.add_argument('--lr', default=1e-1, type=float, help='learning rate')\n",
    "parser.add_argument('--batch_size', default=128, type=int, help='batch size')\n",
    "parser.add_argument('--epoch', default=200, type=int, help='number of training epoch')\n",
    "parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
    "parser.add_argument('--gpu', default=0, type=int, help='specify which gpu to be used')\n",
    "args = parser.parse_args()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)\n",
    "args.model = args.model.lower()\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, model_type, decay_steps, num_classes=10):\n",
    "        if 'lenet' in model_type:\n",
    "            self.model = LeNet(num_classes)\n",
    "        elif 'alexnet' in model_type:\n",
    "            self.model = AlexNet(num_classes)\n",
    "        elif 'vgg' in model_type:\n",
    "            self.model = VGG(model_type, num_classes)\n",
    "        elif 'resnet' in model_type:\n",
    "            if 'se' in model_type:\n",
    "                if 'preact' in model_type:\n",
    "                    self.model = SEPreActResNet(model_type, num_classes)\n",
    "                else:\n",
    "                    self.model = SEResNet(model_type, num_classes)\n",
    "            else:\n",
    "                if 'preact' in model_type:\n",
    "                    self.model = PreActResNet(model_type, num_classes)\n",
    "                else:\n",
    "                    self.model = ResNet(model_type, num_classes)\n",
    "        elif 'densenet' in model_type:\n",
    "            self.model = DenseNet(model_type, num_classes)\n",
    "        elif 'mobilenet' in model_type:\n",
    "            if 'v2' not in model_type:\n",
    "                self.model = MobileNet(num_classes)\n",
    "            else:\n",
    "                self.model = MobileNetV2(num_classes)\n",
    "        else:\n",
    "            sys.exit(ValueError(\"{:s} is currently not supported.\".format(model_type)))\n",
    "        \n",
    "        self.loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "        learning_rate_fn = tf.keras.experimental.CosineDecay(args.lr, decay_steps=decay_steps)\n",
    "        self.optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate_fn, momentum=0.9)\n",
    "        self.weight_decay = 5e-4\n",
    "        \n",
    "        self.train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        self.train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "        self.test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "        self.test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
    "        \n",
    "    @tf.function\n",
    "    def train_step(self, images, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.model(images, training=True)\n",
    "            # Cross-entropy loss\n",
    "            ce_loss = self.loss_object(labels, predictions)\n",
    "            # L2 loss(weight decay)\n",
    "            l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in self.model.trainable_variables])\n",
    "            loss = ce_loss + l2_loss*self.weight_decay\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        \n",
    "        self.train_loss(loss)\n",
    "        self.train_accuracy(labels, predictions)\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, images, labels):\n",
    "        predictions = self.model(images, training=False)\n",
    "        t_loss = self.loss_object(labels, predictions)\n",
    "        \n",
    "        self.test_loss(t_loss)\n",
    "        self.test_accuracy(labels, predictions)\n",
    "        \n",
    "    def train(self, train_ds, test_ds, epoch):\n",
    "        best_acc = tf.Variable(0.0)\n",
    "        curr_epoch = tf.Variable(0)  # start from epoch 0 or last checkpoint epoch\n",
    "        ckpt_path = './checkpoints/{:s}/'.format(args.model)\n",
    "        ckpt = tf.train.Checkpoint(curr_epoch=curr_epoch, best_acc=best_acc,\n",
    "                                   optimizer=self.optimizer, model=self.model)\n",
    "        manager = tf.train.CheckpointManager(ckpt, ckpt_path, max_to_keep=1)\n",
    "        \n",
    "        if args.resume:\n",
    "            # Load checkpoint.\n",
    "            print('==> Resuming from checkpoint...')\n",
    "            assert os.path.isdir(ckpt_path), 'Error: no checkpoint directory found!'\n",
    "\n",
    "            # Restore the weights\n",
    "            ckpt.restore(manager.latest_checkpoint)\n",
    "        \n",
    "        for e in tqdm(range(int(curr_epoch), epoch)):\n",
    "            # Reset the metrics at the start of the next epoch\n",
    "            self.train_loss.reset_states()\n",
    "            self.train_accuracy.reset_states()\n",
    "            self.test_loss.reset_states()\n",
    "            self.test_accuracy.reset_states()\n",
    "\n",
    "            for images, labels in train_ds:\n",
    "                self.train_step(images, labels)\n",
    "                \n",
    "            for images, labels in test_ds:\n",
    "                self.test_step(images, labels)\n",
    "\n",
    "            template = 'Epoch {:0}, Loss: {:.4f}, Accuracy: {:.2f}%, Test Loss: {:.4f}, Test Accuracy: {:.2f}%'\n",
    "            print (template.format(e+1,\n",
    "                                   self.train_loss.result(),\n",
    "                                   self.train_accuracy.result()*100,\n",
    "                                   self.test_loss.result(),\n",
    "                                   self.test_accuracy.result()*100))\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if self.test_accuracy.result() > best_acc:\n",
    "                print('Saving...')\n",
    "                if not os.path.isdir('./checkpoints/'):\n",
    "                    os.mkdir('./checkpoints/')\n",
    "                if not os.path.isdir(ckpt_path):\n",
    "                    os.mkdir(ckpt_path)\n",
    "                best_acc.assign(self.test_accuracy.result())\n",
    "                curr_epoch.assign(e+1)\n",
    "                manager.save()\n",
    "    \n",
    "    def predict(self, pred_ds, best):\n",
    "        if best:\n",
    "            ckpt_path = './checkpoints/{:s}/'.format(args.model)\n",
    "            ckpt = tf.train.Checkpoint(model=self.model)\n",
    "            manager = tf.train.CheckpointManager(ckpt, ckpt_path, max_to_keep=1)\n",
    "            \n",
    "            # Load checkpoint\n",
    "            print('==> Resuming from checkpoint...')\n",
    "            assert os.path.isdir(ckpt_path), 'Error: no checkpoint directory found!'\n",
    "            ckpt.restore(manager.latest_checkpoint)\n",
    "        \n",
    "        self.test_accuracy.reset_states()\n",
    "        for images, labels in pred_ds:\n",
    "            self.test_step(images, labels)\n",
    "        print ('Prediction Accuracy: {:.2f}%'.format(self.test_accuracy.result()*100))\n",
    "\n",
    "def main():\n",
    "    # Data\n",
    "    print('==> Preparing data...')\n",
    "    train_images, train_labels, test_images, test_labels = get_dataset()\n",
    "    mean, std = get_mean_and_std(train_images)\n",
    "    train_images = normalize(train_images, mean, std)\n",
    "    test_images = normalize(test_images, mean, std)\n",
    "\n",
    "    train_ds = dataset_generator(train_images, train_labels, args.batch_size)\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).\\\n",
    "            batch(args.batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    decay_steps = int(args.epoch*len(train_images)/args.batch_size)\n",
    "    \n",
    "    # Train\n",
    "    print('==> Building model...')\n",
    "    model = Model(args.model, decay_steps)\n",
    "    model.train(train_ds, test_ds, args.epoch)\n",
    "    \n",
    "    # Evaluate\n",
    "    model.predict(test_ds, best=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DenseNet Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from typing import Any, List, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as cp\n",
    "from torch import Tensor\n",
    "\n",
    "from ..transforms._presets import ImageClassification\n",
    "from ..utils import _log_api_usage_once\n",
    "from ._api import register_model, Weights, WeightsEnum\n",
    "from ._meta import _IMAGENET_CATEGORIES\n",
    "from ._utils import _ovewrite_named_param, handle_legacy_interface\n",
    "\n",
    "__all__ = [\n",
    "    \"DenseNet\",\n",
    "    \"DenseNet121_Weights\",\n",
    "    \"DenseNet161_Weights\",\n",
    "    \"DenseNet169_Weights\",\n",
    "    \"DenseNet201_Weights\",\n",
    "    \"densenet121\",\n",
    "    \"densenet161\",\n",
    "    \"densenet169\",\n",
    "    \"densenet201\",\n",
    "]\n",
    "\n",
    "\n",
    "class _DenseLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_input_features: int, growth_rate: int, bn_size: int, drop_rate: float, memory_efficient: bool = False\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.BatchNorm2d(num_input_features)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(num_input_features, bn_size * growth_rate, kernel_size=1, stride=1, bias=False)\n",
    "\n",
    "        self.norm2 = nn.BatchNorm2d(bn_size * growth_rate)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(bn_size * growth_rate, growth_rate, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.drop_rate = float(drop_rate)\n",
    "        self.memory_efficient = memory_efficient\n",
    "\n",
    "    def bn_function(self, inputs: List[Tensor]) -> Tensor:\n",
    "        concated_features = torch.cat(inputs, 1)\n",
    "        bottleneck_output = self.conv1(self.relu1(self.norm1(concated_features)))  # noqa: T484\n",
    "        return bottleneck_output\n",
    "\n",
    "    # todo: rewrite when torchscript supports any\n",
    "    def any_requires_grad(self, input: List[Tensor]) -> bool:\n",
    "        for tensor in input:\n",
    "            if tensor.requires_grad:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    @torch.jit.unused  # noqa: T484\n",
    "    def call_checkpoint_bottleneck(self, input: List[Tensor]) -> Tensor:\n",
    "        def closure(*inputs):\n",
    "            return self.bn_function(inputs)\n",
    "\n",
    "        return cp.checkpoint(closure, *input, use_reentrant=False)\n",
    "\n",
    "    @torch.jit._overload_method  # noqa: F811\n",
    "    def forward(self, input: List[Tensor]) -> Tensor:  # noqa: F811\n",
    "        pass\n",
    "\n",
    "    @torch.jit._overload_method  # noqa: F811\n",
    "    def forward(self, input: Tensor) -> Tensor:  # noqa: F811\n",
    "        pass\n",
    "\n",
    "    # torchscript does not yet support *args, so we overload method\n",
    "    # allowing it to take either a List[Tensor] or single Tensor\n",
    "    def forward(self, input: Tensor) -> Tensor:  # noqa: F811\n",
    "        if isinstance(input, Tensor):\n",
    "            prev_features = [input]\n",
    "        else:\n",
    "            prev_features = input\n",
    "\n",
    "        if self.memory_efficient and self.any_requires_grad(prev_features):\n",
    "            if torch.jit.is_scripting():\n",
    "                raise Exception(\"Memory Efficient not supported in JIT\")\n",
    "\n",
    "            bottleneck_output = self.call_checkpoint_bottleneck(prev_features)\n",
    "        else:\n",
    "            bottleneck_output = self.bn_function(prev_features)\n",
    "\n",
    "        new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "        return new_features\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.ModuleDict):\n",
    "    _version = 2\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers: int,\n",
    "        num_input_features: int,\n",
    "        bn_size: int,\n",
    "        growth_rate: int,\n",
    "        drop_rate: float,\n",
    "        memory_efficient: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(\n",
    "                num_input_features + i * growth_rate,\n",
    "                growth_rate=growth_rate,\n",
    "                bn_size=bn_size,\n",
    "                drop_rate=drop_rate,\n",
    "                memory_efficient=memory_efficient,\n",
    "            )\n",
    "            self.add_module(\"denselayer%d\" % (i + 1), layer)\n",
    "\n",
    "    def forward(self, init_features: Tensor) -> Tensor:\n",
    "        features = [init_features]\n",
    "        for name, layer in self.items():\n",
    "            new_features = layer(features)\n",
    "            features.append(new_features)\n",
    "        return torch.cat(features, 1)\n",
    "\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, num_input_features: int, num_output_features: int) -> None:\n",
    "        super().__init__()\n",
    "        self.norm = nn.BatchNorm2d(num_input_features)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(num_input_features, num_output_features, kernel_size=1, stride=1, bias=False)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    r\"\"\"Densenet-BC model class, based on\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_.\n",
    "\n",
    "    Args:\n",
    "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
    "        block_config (list of 4 ints) - how many layers in each pooling block\n",
    "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
    "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
    "          (i.e. bn_size * k features in the bottleneck layer)\n",
    "        drop_rate (float) - dropout rate after each dense layer\n",
    "        num_classes (int) - number of classification classes\n",
    "        memory_efficient (bool) - If True, uses checkpointing. Much more memory efficient,\n",
    "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        growth_rate: int = 32,\n",
    "        block_config: Tuple[int, int, int, int] = (6, 12, 24, 16),\n",
    "        num_init_features: int = 64,\n",
    "        bn_size: int = 4,\n",
    "        drop_rate: float = 0,\n",
    "        num_classes: int = 1000,\n",
    "        memory_efficient: bool = False,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        _log_api_usage_once(self)\n",
    "\n",
    "        # First convolution\n",
    "        self.features = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\"conv0\", nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n",
    "                    (\"norm0\", nn.BatchNorm2d(num_init_features)),\n",
    "                    (\"relu0\", nn.ReLU(inplace=True)),\n",
    "                    (\"pool0\", nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Each denseblock\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(\n",
    "                num_layers=num_layers,\n",
    "                num_input_features=num_features,\n",
    "                bn_size=bn_size,\n",
    "                growth_rate=growth_rate,\n",
    "                drop_rate=drop_rate,\n",
    "                memory_efficient=memory_efficient,\n",
    "            )\n",
    "            self.features.add_module(\"denseblock%d\" % (i + 1), block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
    "                self.features.add_module(\"transition%d\" % (i + 1), trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "        # Final batch norm\n",
    "        self.features.add_module(\"norm5\", nn.BatchNorm2d(num_features))\n",
    "\n",
    "        # Linear layer\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "        # Official init from torch repo.\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        features = self.features(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def _load_state_dict(model: nn.Module, weights: WeightsEnum, progress: bool) -> None:\n",
    "    # '.'s are no longer allowed in module names, but previous _DenseLayer\n",
    "    # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
    "    # They are also in the checkpoints in model_urls. This pattern is used\n",
    "    # to find such keys.\n",
    "    pattern = re.compile(\n",
    "        r\"^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$\"\n",
    "    )\n",
    "\n",
    "    state_dict = weights.get_state_dict(progress=progress, check_hash=True)\n",
    "    for key in list(state_dict.keys()):\n",
    "        res = pattern.match(key)\n",
    "        if res:\n",
    "            new_key = res.group(1) + res.group(2)\n",
    "            state_dict[new_key] = state_dict[key]\n",
    "            del state_dict[key]\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "def _densenet(\n",
    "    growth_rate: int,\n",
    "    block_config: Tuple[int, int, int, int],\n",
    "    num_init_features: int,\n",
    "    weights: Optional[WeightsEnum],\n",
    "    progress: bool,\n",
    "    **kwargs: Any,\n",
    ") -> DenseNet:\n",
    "    if weights is not None:\n",
    "        _ovewrite_named_param(kwargs, \"num_classes\", len(weights.meta[\"categories\"]))\n",
    "\n",
    "    model = DenseNet(growth_rate, block_config, num_init_features, **kwargs)\n",
    "\n",
    "    if weights is not None:\n",
    "        _load_state_dict(model=model, weights=weights, progress=progress)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "_COMMON_META = {\n",
    "    \"min_size\": (29, 29),\n",
    "    \"categories\": _IMAGENET_CATEGORIES,\n",
    "    \"recipe\": \"https://github.com/pytorch/vision/pull/116\",\n",
    "    \"_docs\": \"\"\"These weights are ported from LuaTorch.\"\"\",\n",
    "}\n",
    "\n",
    "\n",
    "class DenseNet121_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/densenet121-a639ec97.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 7978856,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 74.434,\n",
    "                    \"acc@5\": 91.972,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 2.834,\n",
    "            \"_file_size\": 30.845,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "\n",
    "class DenseNet161_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/densenet161-8d451a50.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 28681000,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 77.138,\n",
    "                    \"acc@5\": 93.560,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 7.728,\n",
    "            \"_file_size\": 110.369,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "\n",
    "class DenseNet169_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/densenet169-b2777c0a.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 14149480,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 75.600,\n",
    "                    \"acc@5\": 92.806,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 3.36,\n",
    "            \"_file_size\": 54.708,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "\n",
    "class DenseNet201_Weights(WeightsEnum):\n",
    "    IMAGENET1K_V1 = Weights(\n",
    "        url=\"https://download.pytorch.org/models/densenet201-c1103571.pth\",\n",
    "        transforms=partial(ImageClassification, crop_size=224),\n",
    "        meta={\n",
    "            **_COMMON_META,\n",
    "            \"num_params\": 20013928,\n",
    "            \"_metrics\": {\n",
    "                \"ImageNet-1K\": {\n",
    "                    \"acc@1\": 76.896,\n",
    "                    \"acc@5\": 93.370,\n",
    "                }\n",
    "            },\n",
    "            \"_ops\": 4.291,\n",
    "            \"_file_size\": 77.373,\n",
    "        },\n",
    "    )\n",
    "    DEFAULT = IMAGENET1K_V1\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", DenseNet121_Weights.IMAGENET1K_V1))\n",
    "def densenet121(*, weights: Optional[DenseNet121_Weights] = None, progress: bool = True, **kwargs: Any) -> DenseNet:\n",
    "    r\"\"\"Densenet-121 model from\n",
    "    `Densely Connected Convolutional Networks <https://arxiv.org/abs/1608.06993>`_.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.DenseNet121_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.DenseNet121_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.densenet.DenseNet``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/densenet.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.DenseNet121_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = DenseNet121_Weights.verify(weights)\n",
    "\n",
    "    return _densenet(32, (6, 12, 24, 16), 64, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", DenseNet161_Weights.IMAGENET1K_V1))\n",
    "def densenet161(*, weights: Optional[DenseNet161_Weights] = None, progress: bool = True, **kwargs: Any) -> DenseNet:\n",
    "    r\"\"\"Densenet-161 model from\n",
    "    `Densely Connected Convolutional Networks <https://arxiv.org/abs/1608.06993>`_.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.DenseNet161_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.DenseNet161_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.densenet.DenseNet``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/densenet.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.DenseNet161_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = DenseNet161_Weights.verify(weights)\n",
    "\n",
    "    return _densenet(48, (6, 12, 36, 24), 96, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", DenseNet169_Weights.IMAGENET1K_V1))\n",
    "def densenet169(*, weights: Optional[DenseNet169_Weights] = None, progress: bool = True, **kwargs: Any) -> DenseNet:\n",
    "    r\"\"\"Densenet-169 model from\n",
    "    `Densely Connected Convolutional Networks <https://arxiv.org/abs/1608.06993>`_.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.DenseNet169_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.DenseNet169_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.densenet.DenseNet``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/densenet.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.DenseNet169_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = DenseNet169_Weights.verify(weights)\n",
    "\n",
    "    return _densenet(32, (6, 12, 32, 32), 64, weights, progress, **kwargs)\n",
    "\n",
    "\n",
    "@register_model()\n",
    "@handle_legacy_interface(weights=(\"pretrained\", DenseNet201_Weights.IMAGENET1K_V1))\n",
    "def densenet201(*, weights: Optional[DenseNet201_Weights] = None, progress: bool = True, **kwargs: Any) -> DenseNet:\n",
    "    r\"\"\"Densenet-201 model from\n",
    "    `Densely Connected Convolutional Networks <https://arxiv.org/abs/1608.06993>`_.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.DenseNet201_Weights`, optional): The\n",
    "            pretrained weights to use. See\n",
    "            :class:`~torchvision.models.DenseNet201_Weights` below for\n",
    "            more details, and possible values. By default, no pre-trained\n",
    "            weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.densenet.DenseNet``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/densenet.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.DenseNet201_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    weights = DenseNet201_Weights.verify(weights)\n",
    "\n",
    "    return _densenet(32, (6, 12, 48, 32), 64, weights, progress, **kwargs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
