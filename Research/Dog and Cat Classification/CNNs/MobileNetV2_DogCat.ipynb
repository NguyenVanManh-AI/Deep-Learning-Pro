{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21342,"status":"ok","timestamp":1711556155328,"user":{"displayName":"Hoang Phuc Nguyen Van","userId":"13905269449378512597"},"user_tz":-420},"id":"uHANNl3ZHZbj","outputId":"500b194f-06da-4dd6-cfb3-c4275d8950b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NGJp8xkEfVsy"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/5_AIADVANCE')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"--SpAhB2HMh1"},"outputs":[],"source":["# !unzip /content/drive/MyDrive/5_AIADVANCE/GK_AI_Advance/dogs-vs-cats.zip -d /content/drive/MyDrive/5_AIADVANCE/GK_AI_Advance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jozjddvqHLL-"},"outputs":[],"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, concatenate, BatchNormalization, Dropout, Activation, MaxPooling2D, GlobalAveragePooling2D, Dense, Add\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from imutils import paths\n","import pandas as pd\n","import random\n","from sklearn.preprocessing import LabelEncoder\n","from keras.preprocessing.image import img_to_array\n","from keras.applications import imagenet_utils\n","from keras.preprocessing.image import load_img\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report , confusion_matrix\n","import os\n","import tensorflow as tf\n","from keras.callbacks import ModelCheckpoint\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"markdown","metadata":{"id":"nB5WABmxHLMG"},"source":["#### Tiền xử lí dữ liệu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"goPpQc5nsDcO"},"outputs":[],"source":["root_dir = '/content/drive/MyDrive/5_AIADVANCE/GK_AI_Advance/'\n","\n","# Đường dẫn tới thư mục con 'train', 'val' và 'test'\n","train_dir = os.path.join(root_dir, 'train')\n","val_dir = os.path.join(root_dir, 'val')\n","test_dir = os.path.join(root_dir, 'test')"]},{"cell_type":"markdown","metadata":{"id":"3Peqtq_Af9Cq"},"source":["## Cur"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":421,"status":"ok","timestamp":1711556455621,"user":{"displayName":"Hoang Phuc Nguyen Van","userId":"13905269449378512597"},"user_tz":-420},"id":"6IiQHXhIcucn","outputId":"d4a999a1-41e2-463a-b26b-d2bbe87cd8f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 3499 images belonging to 2 classes.\n","Found 892 images belonging to 2 classes.\n","Found 244 images belonging to 2 classes.\n"]}],"source":["img_size = (224 , 224)\n","batch_size = 8\n","img_shape = (img_size[0] , img_size[1] , 3)\n","\n","tr_gen = ImageDataGenerator()\n","ts_gen = ImageDataGenerator()\n","\n","train_gen = tr_gen.flow_from_directory(train_dir , target_size = img_size , class_mode = 'binary' ,\n","                                       color_mode = 'rgb' , shuffle = True , batch_size = batch_size)\n","\n","valid_gen = ts_gen.flow_from_directory(val_dir , target_size = img_size , class_mode = 'binary' ,\n","                                       color_mode = 'rgb' , shuffle = True , batch_size = batch_size)\n","\n","test_gen = ts_gen.flow_from_directory(test_dir , target_size = img_size , class_mode = 'binary' ,\n","                                       color_mode = 'rgb' , shuffle = False , batch_size = batch_size)"]},{"cell_type":"markdown","metadata":{"id":"t1OlqLs3HLMh"},"source":["#### Xây dựng Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aHo6M1aCez3W"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","class Block(tf.keras.Model):\n","    def __init__(self, in_channels, out_channels, expansion, strides):\n","        super(Block, self).__init__()\n","        self.strides = strides\n","        channels = expansion * in_channels\n","\n","        self.conv1 = layers.Conv2D(channels, kernel_size=1, use_bias=False)\n","        self.bn1 = layers.BatchNormalization()\n","        self.conv2 = layers.Conv2D(channels, kernel_size=3, strides=strides, padding='same',\n","                                   groups=channels, use_bias=False)\n","        self.bn2 = layers.BatchNormalization()\n","        self.conv3 = layers.Conv2D(out_channels, kernel_size=1, use_bias=False)\n","        self.bn3 = layers.BatchNormalization()\n","\n","        if strides == 1 and in_channels != out_channels:\n","            self.shortcut = tf.keras.Sequential([\n","                layers.Conv2D(out_channels, kernel_size=1, use_bias=False),\n","                layers.BatchNormalization()\n","            ])\n","        else:\n","            self.shortcut = lambda x: x\n","\n","    def call(self, x):\n","        out = tf.keras.activations.relu(self.bn1(self.conv1(x)))\n","        out = tf.keras.activations.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out = layers.add([self.shortcut(x), out]) if self.strides==1 else out\n","        return out\n","\n","class MobileNetV2(tf.keras.Model):\n","    config = [(1, 16, 1, 1),\n","              (6, 24, 2, 1),\n","              (6, 32, 3, 2),\n","              (6, 64, 4, 2),\n","              (6, 96, 3, 1),\n","              (6, 160, 3, 2),\n","              (6, 320, 1, 1)]\n","\n","    def __init__(self, num_classes):\n","        super(MobileNetV2, self).__init__()\n","        self.conv1 = layers.Conv2D(32, kernel_size=3, padding='same', use_bias=False)\n","        self.bn1 = layers.BatchNormalization()\n","        self.layer = self._make_layers(in_channels=32)\n","        self.conv2 = layers.Conv2D(1280, kernel_size=1, use_bias=False)\n","        self.bn2 = layers.BatchNormalization()\n","        self.avg_pool2d = layers.AveragePooling2D(pool_size=4)\n","        self.flatten = layers.Flatten()\n","        self.fc = layers.Dense(num_classes, activation='softmax')\n","\n","    def call(self, x):\n","        out = tf.keras.activations.relu(self.bn1(self.conv1(x)))\n","        out = self.layer(out)\n","        out = tf.keras.activations.relu(self.bn2(self.conv2(out)))\n","        out = self.avg_pool2d(out)\n","        out = self.flatten(out)\n","        out = self.fc(out)\n","        return out\n","\n","    def _make_layers(self, in_channels):\n","        layer = []\n","        for expansion, out_channels, num_blocks, strides in self.config:\n","            stride = [strides] + [1]*(num_blocks-1)\n","            for s in stride:\n","                layer += [Block(in_channels, out_channels, expansion, s)]\n","                in_channels = out_channels\n","        return tf.keras.Sequential(layer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mfUF9cgMibRU"},"outputs":[],"source":["mobileNetV2 = MobileNetV2(num_classes = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2654,"status":"ok","timestamp":1711556464390,"user":{"displayName":"Hoang Phuc Nguyen Van","userId":"13905269449378512597"},"user_tz":-420},"id":"PP3ON1EPim6U","outputId":"ebbec31e-91d4-4cab-de8f-2ce8d10d2f26"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"mobile_net_v2_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_57 (Conv2D)          multiple                  864       \n","                                                                 \n"," batch_normalization_57 (Ba  multiple                  128       \n"," tchNormalization)                                               \n","                                                                 \n"," sequential_9 (Sequential)   (1, 28, 28, 320)          1903488   \n","                                                                 \n"," conv2d_113 (Conv2D)         multiple                  409600    \n","                                                                 \n"," batch_normalization_113 (B  multiple                  5120      \n"," atchNormalization)                                              \n","                                                                 \n"," average_pooling2d_1 (Avera  multiple                  0         \n"," gePooling2D)                                                    \n","                                                                 \n"," flatten_1 (Flatten)         multiple                  0         \n","                                                                 \n"," dense_1 (Dense)             multiple                  125442    \n","                                                                 \n","=================================================================\n","Total params: 2444642 (9.33 MB)\n","Trainable params: 2409554 (9.19 MB)\n","Non-trainable params: 35088 (137.06 KB)\n","_________________________________________________________________\n"]}],"source":["mobileNetV2.build((1, 224, 224, 3))\n","mobileNetV2.summary()"]},{"cell_type":"markdown","metadata":{"id":"HK0MVUowHLMk"},"source":["#### Fit model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FpyzQCofHLMl","outputId":"542a1344-f504-499c-c86c-bf4ae8ecdb2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","437/437 [==============================] - ETA: 0s - loss: 1.2024 - accuracy: 0.6184\n","Epoch 1: val_loss improved from inf to 0.79339, saving model to models/model-MobileNetV2-001.keras\n","437/437 [==============================] - 680s 1s/step - loss: 1.2024 - accuracy: 0.6184 - val_loss: 0.7934 - val_accuracy: 0.4561\n","Epoch 2/20\n","437/437 [==============================] - ETA: 0s - loss: 0.5888 - accuracy: 0.6918\n","Epoch 2: val_loss improved from 0.79339 to 0.63643, saving model to models/model-MobileNetV2-002.keras\n","437/437 [==============================] - 218s 498ms/step - loss: 0.5888 - accuracy: 0.6918 - val_loss: 0.6364 - val_accuracy: 0.6486\n","Epoch 3/20\n","437/437 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.7282\n","Epoch 3: val_loss did not improve from 0.63643\n","437/437 [==============================] - 217s 496ms/step - loss: 0.5476 - accuracy: 0.7282 - val_loss: 0.7317 - val_accuracy: 0.6396\n","Epoch 4/20\n","437/437 [==============================] - ETA: 0s - loss: 0.5199 - accuracy: 0.7516\n","Epoch 4: val_loss improved from 0.63643 to 0.51750, saving model to models/model-MobileNetV2-004.keras\n","437/437 [==============================] - 211s 483ms/step - loss: 0.5199 - accuracy: 0.7516 - val_loss: 0.5175 - val_accuracy: 0.7568\n","Epoch 5/20\n","437/437 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.7496\n","Epoch 5: val_loss did not improve from 0.51750\n","437/437 [==============================] - 217s 496ms/step - loss: 0.5256 - accuracy: 0.7496 - val_loss: 0.5994 - val_accuracy: 0.7286\n","Epoch 6/20\n","437/437 [==============================] - ETA: 0s - loss: 0.4954 - accuracy: 0.7697\n","Epoch 6: val_loss did not improve from 0.51750\n","437/437 [==============================] - 217s 496ms/step - loss: 0.4954 - accuracy: 0.7697 - val_loss: 0.5296 - val_accuracy: 0.7523\n","Epoch 7/20\n","437/437 [==============================] - ETA: 0s - loss: 0.4710 - accuracy: 0.7797\n","Epoch 7: val_loss did not improve from 0.51750\n","437/437 [==============================] - 217s 496ms/step - loss: 0.4710 - accuracy: 0.7797 - val_loss: 0.5642 - val_accuracy: 0.7455\n","Epoch 8/20\n","437/437 [==============================] - ETA: 0s - loss: 0.4571 - accuracy: 0.7886\n","Epoch 8: val_loss did not improve from 0.51750\n","437/437 [==============================] - 217s 496ms/step - loss: 0.4571 - accuracy: 0.7886 - val_loss: 0.5396 - val_accuracy: 0.7342\n","Epoch 9/20\n","437/437 [==============================] - ETA: 0s - loss: 0.4454 - accuracy: 0.7932\n","Epoch 9: val_loss did not improve from 0.51750\n","437/437 [==============================] - 210s 481ms/step - loss: 0.4454 - accuracy: 0.7932 - val_loss: 0.5531 - val_accuracy: 0.7624\n","Epoch 10/20\n","437/437 [==============================] - ETA: 0s - loss: 0.4347 - accuracy: 0.8006\n","Epoch 10: val_loss did not improve from 0.51750\n","437/437 [==============================] - 210s 480ms/step - loss: 0.4347 - accuracy: 0.8006 - val_loss: 0.6617 - val_accuracy: 0.7241\n","Epoch 11/20\n","437/437 [==============================] - ETA: 0s - loss: 0.4109 - accuracy: 0.8084\n","Epoch 11: val_loss did not improve from 0.51750\n","437/437 [==============================] - 217s 496ms/step - loss: 0.4109 - accuracy: 0.8084 - val_loss: 0.7186 - val_accuracy: 0.7275\n","Epoch 12/20\n","437/437 [==============================] - ETA: 0s - loss: 0.4136 - accuracy: 0.8078\n","Epoch 12: val_loss improved from 0.51750 to 0.51419, saving model to models/model-MobileNetV2-012.keras\n","437/437 [==============================] - 218s 498ms/step - loss: 0.4136 - accuracy: 0.8078 - val_loss: 0.5142 - val_accuracy: 0.7928\n","Epoch 13/20\n","437/437 [==============================] - ETA: 0s - loss: 0.3972 - accuracy: 0.8210\n","Epoch 13: val_loss improved from 0.51419 to 0.50115, saving model to models/model-MobileNetV2-013.keras\n","437/437 [==============================] - 218s 498ms/step - loss: 0.3972 - accuracy: 0.8210 - val_loss: 0.5011 - val_accuracy: 0.7793\n","Epoch 14/20\n","437/437 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.8324\n","Epoch 14: val_loss did not improve from 0.50115\n","437/437 [==============================] - 217s 496ms/step - loss: 0.3801 - accuracy: 0.8324 - val_loss: 0.5257 - val_accuracy: 0.7872\n","Epoch 15/20\n","437/437 [==============================] - ETA: 0s - loss: 0.3707 - accuracy: 0.8356\n","Epoch 15: val_loss did not improve from 0.50115\n","437/437 [==============================] - 217s 496ms/step - loss: 0.3707 - accuracy: 0.8356 - val_loss: 0.6342 - val_accuracy: 0.7646\n","Epoch 16/20\n","437/437 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.8462\n","Epoch 16: val_loss did not improve from 0.50115\n","437/437 [==============================] - 217s 496ms/step - loss: 0.3494 - accuracy: 0.8462 - val_loss: 0.5085 - val_accuracy: 0.7905\n","Epoch 17/20\n","437/437 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.8522\n","Epoch 17: val_loss improved from 0.50115 to 0.43832, saving model to models/model-MobileNetV2-017.keras\n","437/437 [==============================] - 211s 482ms/step - loss: 0.3415 - accuracy: 0.8522 - val_loss: 0.4383 - val_accuracy: 0.7950\n","Epoch 18/20\n","144/437 [========>.....................] - ETA: 2:11 - loss: 0.3031 - accuracy: 0.8628"]}],"source":["# Tạo đối tượng optimizer  # SGD\n","optimizer = tf.keras.optimizers.Adam()\n","\n","# Thiết lập ModelCheckpoint\n","save_best_only = True\n","checkpoint = ModelCheckpoint('models/model-MobileNetV2-{epoch:03d}.keras',\n","                             monitor='val_loss',\n","                             verbose=1,\n","                             save_best_only=save_best_only,\n","                             mode='auto')\n","\n","# Xây dựng quy trình huấn luyện\n","mobileNetV2.compile(optimizer=optimizer,\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Huấn luyện mô hình với dữ liệu đã chuẩn bị\n","# H = model.fit(X_train, y_train, epochs=10, batch_size=8, validation_split=0.2, callbacks=[checkpoint])\n","H = mobileNetV2.fit(\n","    train_gen,\n","    steps_per_epoch = train_gen.samples // train_gen.batch_size,\n","    validation_data = valid_gen,\n","    validation_steps = valid_gen.samples // valid_gen.batch_size,\n","    epochs = 20,\n","    callbacks=[checkpoint]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xCUoKeI5HLMu"},"outputs":[],"source":["# Vẽ đồ thị loss, accuracy của traning set và validation set\n","fig = plt.figure()\n","numOfEpoch = 10\n","plt.plot(np.arange(0, numOfEpoch), H.history['loss'], label='training loss')\n","plt.plot(np.arange(0, numOfEpoch), H.history['val_loss'], label='validation loss')\n","plt.plot(np.arange(0, numOfEpoch), H.history['accuracy'], label='accuracy') # sử dụng từ khóa accuracy thay vì acc\n","plt.plot(np.arange(0, numOfEpoch), H.history['val_accuracy'], label='validation accuracy') # sử dụng từ khóa val_accuracy thay vì val_acc\n","plt.title('Accuracy and Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss|Accuracy')\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bynfnBlcHLMw"},"outputs":[],"source":["from keras.models import load_model\n","model = load_model('models/model-ResNet50-009.keras')\n","\n","score = model.evaluate(X_test, y_test, verbose=1)\n","print(score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dPrO7ufjHLMy"},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"leNIVyuOHLM1"},"outputs":[],"source":["# Đánh giá model\n","preds = model.predict(X_test) # DỰ ĐOÁN VÀ ĐÁNH GIÁ\n","preds = np.argmax(preds, axis=1)\n","print(classification_report(y_test, preds))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttKmAVfUHLM4"},"outputs":[],"source":["# 10. Dự đoán ảnh\n","plt.imshow(X_test[0])\n","plt.axis('off')\n","plt.show()\n","\n","y_predict = model.predict(np.expand_dims(X_test[0], axis=0))\n","print('Giá trị dự đoán: ', np.argmax(y_predict))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqfUxF13HLM6"},"outputs":[],"source":["# Tạo ma trận nhầm lẫn\n","cm = confusion_matrix(y_test, preds)\n","\n","# Chuyển nhãn số thành tên\n","label_names = le.inverse_transform(np.unique(y_test))\n","label_names = [label.split('/')[-1] for label in label_names]\n","# Sắp xếp lại ma trận nhầm lẫn\n","sorted_cm = cm[np.argsort(label_names)][:, np.argsort(label_names)]\n","\n","# Tạo dataframe từ ma trận nhầm lẫn đã sắp xếp lại\n","df_cm = pd.DataFrame(sorted_cm, index=label_names, columns=label_names)\n","\n","# Vẽ ma trận nhầm lẫn\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(df_cm, annot=True, cmap='Blues', fmt='g')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.show()\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
