{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19248,"status":"ok","timestamp":1711556914261,"user":{"displayName":"Tiến Phạm Văn","userId":"14533299267554458210"},"user_tz":-420},"id":"uHANNl3ZHZbj","outputId":"23056160-665c-4d96-edeb-f35208a16750"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NGJp8xkEfVsy"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/5_AIADVANCE')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"--SpAhB2HMh1"},"outputs":[],"source":["# !unzip /content/drive/MyDrive/5_AIADVANCE/GK_AI_Advance/dogs-vs-cats.zip -d /content/drive/MyDrive/5_AIADVANCE/GK_AI_Advance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jozjddvqHLL-"},"outputs":[],"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, concatenate, BatchNormalization, Dropout, Activation, MaxPooling2D, GlobalAveragePooling2D, Dense, Add\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from imutils import paths\n","import pandas as pd\n","import random\n","from sklearn.preprocessing import LabelEncoder\n","from keras.preprocessing.image import img_to_array\n","from keras.applications import imagenet_utils\n","from keras.preprocessing.image import load_img\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report , confusion_matrix\n","import os\n","import tensorflow as tf\n","from keras.callbacks import ModelCheckpoint\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"markdown","metadata":{"id":"nB5WABmxHLMG"},"source":["#### Tiền xử lí dữ liệu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J57Ch_YjoiQ-"},"outputs":[],"source":["root_dir = '/content/drive/MyDrive/5_AIADVANCE/GK_AI_Advance/'\n","\n","# Đường dẫn tới thư mục con 'train', 'val' và 'test'\n","train_dir = os.path.join(root_dir, 'train')\n","val_dir = os.path.join(root_dir, 'val')\n","test_dir = os.path.join(root_dir, 'test')"]},{"cell_type":"markdown","metadata":{"id":"3Peqtq_Af9Cq"},"source":["## Cur"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19269,"status":"ok","timestamp":1711556946502,"user":{"displayName":"Tiến Phạm Văn","userId":"14533299267554458210"},"user_tz":-420},"id":"6IiQHXhIcucn","outputId":"2feedc6e-d51b-4e08-ad11-b029193243dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 3499 images belonging to 2 classes.\n","Found 999 images belonging to 2 classes.\n","Found 502 images belonging to 2 classes.\n"]}],"source":["img_size = (224 , 224)\n","batch_size = 8\n","img_shape = (img_size[0] , img_size[1] , 3)\n","\n","tr_gen = ImageDataGenerator()\n","ts_gen = ImageDataGenerator()\n","\n","train_gen = tr_gen.flow_from_directory(train_dir , target_size = img_size , class_mode = 'categorical' ,\n","                                       color_mode = 'rgb' , shuffle = True , batch_size = batch_size)\n","\n","valid_gen = ts_gen.flow_from_directory(val_dir , target_size = img_size , class_mode = 'categorical' ,\n","                                       color_mode = 'rgb' , shuffle = True , batch_size = batch_size)\n","\n","test_gen = ts_gen.flow_from_directory(test_dir , target_size = img_size , class_mode = 'categorical' ,\n","                                       color_mode = 'rgb' , shuffle = False , batch_size = batch_size)"]},{"cell_type":"markdown","metadata":{"id":"t1OlqLs3HLMh"},"source":["#### Xây dựng Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aHo6M1aCez3W"},"outputs":[],"source":["'''\n","ResNet18/34/50/101/152 in TensorFlow2.\n","\n","Reference:\n","[1] He, Kaiming, et al.\n","    \"Deep residual learning for image recognition.\"\n","    Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n","'''\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","import sys\n","\n","class BasicBlock(tf.keras.Model):\n","    expansion = 1\n","\n","    def __init__(self, in_channels, out_channels, strides=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = layers.Conv2D(out_channels, kernel_size=3, strides=strides, padding='same', use_bias=False)\n","        self.bn1 = layers.BatchNormalization()\n","        self.conv2 = layers.Conv2D(out_channels, kernel_size=3, strides=1, padding='same', use_bias=False)\n","        self.bn2 = layers.BatchNormalization()\n","\n","        if strides != 1 or in_channels != self.expansion*out_channels:\n","            self.shortcut = tf.keras.Sequential([\n","                layers.Conv2D(self.expansion*out_channels, kernel_size=1, strides=strides, use_bias=False),\n","                layers.BatchNormalization()\n","            ])\n","        else:\n","            self.shortcut = lambda x: x\n","\n","    def call(self, x):\n","        out = tf.keras.activations.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out = layers.add([self.shortcut(x), out])\n","        out = tf.keras.activations.relu(out)\n","        return out\n","\n","class BottleNeck(tf.keras.Model):\n","    expansion = 4\n","\n","    def __init__(self, in_channels, out_channels, strides=1):\n","        super(BottleNeck, self).__init__()\n","        self.conv1 = layers.Conv2D(out_channels, kernel_size=1, use_bias=False)\n","        self.bn1 = layers.BatchNormalization()\n","        self.conv2 = layers.Conv2D(out_channels, kernel_size=3, strides=strides, padding='same', use_bias=False)\n","        self.bn2 = layers.BatchNormalization()\n","        self.conv3 = layers.Conv2D(self.expansion*out_channels, kernel_size=1, use_bias=False)\n","        self.bn3 = layers.BatchNormalization()\n","\n","        if strides != 1 or in_channels != self.expansion*out_channels:\n","            self.shortcut = tf.keras.Sequential([\n","                layers.Conv2D(self.expansion*out_channels, kernel_size=1, strides=strides, use_bias=False),\n","                layers.BatchNormalization()\n","            ])\n","        else:\n","            self.shortcut = lambda x: x\n","\n","    def call(self, x):\n","        out = tf.keras.activations.relu(self.bn1(self.conv1(x)))\n","        out = tf.keras.activations.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out = layers.add([self.shortcut(x), out])\n","        out = tf.keras.activations.relu(out)\n","        return out\n","\n","class BuildResNet(tf.keras.Model):\n","    def __init__(self, block, num_blocks, num_classes):\n","        super(BuildResNet, self).__init__()\n","        self.in_channels = 64\n","\n","        self.conv1 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n","        self.bn1 = layers.BatchNormalization()\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], strides=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], strides=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], strides=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], strides=2)\n","        self.avg_pool2d = layers.AveragePooling2D(pool_size=4)\n","        self.flatten = layers.Flatten()\n","        self.fc = layers.Dense(num_classes, activation='softmax')\n","\n","    def call(self, x):\n","        out = tf.keras.activations.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = self.avg_pool2d(out)\n","        out = self.flatten(out)\n","        out = self.fc(out)\n","        return out\n","\n","    def _make_layer(self, block, out_channels, num_blocks, strides):\n","        stride = [strides] + [1]*(num_blocks-1)\n","        layer = []\n","        for s in stride:\n","            layer += [block(self.in_channels, out_channels, s)]\n","            self.in_channels = out_channels * block.expansion\n","        return tf.keras.Sequential(layer)\n","\n","    def get_config(self):\n","        config = {\n","          'block': self.block,\n","          'num_blocks': self.num_blocks,\n","          'num_classes': self.num_classes\n","        }\n","        return config\n","\n","def ResNet(model_type, num_classes):\n","    if model_type == 'resnet18':\n","        return BuildResNet(BasicBlock, [2, 2, 2, 2], num_classes)\n","    elif model_type == 'resnet34':\n","        return BuildResNet(BasicBlock, [3, 4, 6, 3], num_classes)\n","    elif model_type == 'resnet50':\n","        return BuildResNet(BottleNeck, [3, 4, 6, 3], num_classes)\n","    elif model_type == 'resnet101':\n","        return BuildResNet(BottleNeck, [3, 4, 23, 3], num_classes)\n","    elif model_type == 'resnet152':\n","        return BuildResNet(BottleNeck, [3, 8, 36, 3], num_classes)\n","    else:\n","        sys.exit(ValueError(\"{:s} is currently not supported.\".format(model_type)))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mfUF9cgMibRU"},"outputs":[],"source":["resnet50 = ResNet(model_type = 'resnet50', num_classes = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3791,"status":"ok","timestamp":1711556951730,"user":{"displayName":"Tiến Phạm Văn","userId":"14533299267554458210"},"user_tz":-420},"id":"PP3ON1EPim6U","outputId":"be5b9ea7-5618-4736-8c31-a5c6e4bb093b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"build_res_net\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             multiple                  1728      \n","                                                                 \n"," batch_normalization (Batch  multiple                  256       \n"," Normalization)                                                  \n","                                                                 \n"," sequential_1 (Sequential)   (1, 224, 224, 256)        218624    \n","                                                                 \n"," sequential_3 (Sequential)   (1, 112, 112, 512)        1226752   \n","                                                                 \n"," sequential_5 (Sequential)   (1, 56, 56, 1024)         7118848   \n","                                                                 \n"," sequential_7 (Sequential)   (1, 28, 28, 2048)         14987264  \n","                                                                 \n"," average_pooling2d (Average  multiple                  0         \n"," Pooling2D)                                                      \n","                                                                 \n"," flatten (Flatten)           multiple                  0         \n","                                                                 \n"," dense (Dense)               multiple                  200706    \n","                                                                 \n","=================================================================\n","Total params: 23754178 (90.61 MB)\n","Trainable params: 23701058 (90.41 MB)\n","Non-trainable params: 53120 (207.50 KB)\n","_________________________________________________________________\n"]}],"source":["resnet50.build((1, 224, 224, 3))\n","resnet50.summary()"]},{"cell_type":"markdown","metadata":{"id":"HK0MVUowHLMk"},"source":["#### Fit model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"FpyzQCofHLMl","outputId":"0617af4e-5866-4514-f5f9-6d04e25403a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","437/437 [==============================] - ETA: 0s - loss: 2.5152 - accuracy: 0.5571\n","Epoch 1: val_loss improved from inf to 0.80052, saving model to models/model-ResNet50-001.keras\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"]},{"name":"stdout","output_type":"stream","text":["437/437 [==============================] - 1230s 3s/step - loss: 2.5152 - accuracy: 0.5571 - val_loss: 0.8005 - val_accuracy: 0.5706\n","Epoch 2/20\n","437/437 [==============================] - ETA: 0s - loss: 0.6607 - accuracy: 0.6419\n","Epoch 2: val_loss improved from 0.80052 to 0.62303, saving model to models/model-ResNet50-002.keras\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"]},{"name":"stdout","output_type":"stream","text":["437/437 [==============================] - 593s 1s/step - loss: 0.6607 - accuracy: 0.6419 - val_loss: 0.6230 - val_accuracy: 0.6573\n","Epoch 3/20\n","437/437 [==============================] - ETA: 0s - loss: 0.6536 - accuracy: 0.6465\n","Epoch 3: val_loss improved from 0.62303 to 0.58510, saving model to models/model-ResNet50-003.keras\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"]},{"name":"stdout","output_type":"stream","text":["437/437 [==============================] - 593s 1s/step - loss: 0.6536 - accuracy: 0.6465 - val_loss: 0.5851 - val_accuracy: 0.6804\n","Epoch 4/20\n","437/437 [==============================] - ETA: 0s - loss: 0.5846 - accuracy: 0.6941\n","Epoch 4: val_loss did not improve from 0.58510\n","437/437 [==============================] - 630s 1s/step - loss: 0.5846 - accuracy: 0.6941 - val_loss: 0.7059 - val_accuracy: 0.6381\n","Epoch 5/20\n","437/437 [==============================] - ETA: 0s - loss: 0.5677 - accuracy: 0.7095\n","Epoch 5: val_loss did not improve from 0.58510\n","437/437 [==============================] - 591s 1s/step - loss: 0.5677 - accuracy: 0.7095 - val_loss: 0.7078 - val_accuracy: 0.6966\n","Epoch 6/20\n","388/437 [=========================>....] - ETA: 1:01 - loss: 0.5775 - accuracy: 0.7125"]}],"source":["# Tạo đối tượng optimizer  # SGD\n","optimizer = tf.keras.optimizers.Adam()\n","\n","# Thiết lập ModelCheckpoint\n","save_best_only = True\n","checkpoint = ModelCheckpoint('models/model-ResNet50-{epoch:03d}.keras',\n","                             monitor='val_loss',\n","                             verbose=1,\n","                             save_best_only=save_best_only,\n","                             mode='auto')\n","\n","# Xây dựng quy trình huấn luyện\n","resnet50.compile(optimizer=optimizer,\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Huấn luyện mô hình với dữ liệu đã chuẩn bị\n","# H = model.fit(X_train, y_train, epochs=10, batch_size=8, validation_split=0.2, callbacks=[checkpoint])\n","H = resnet50.fit(\n","    train_gen,\n","    steps_per_epoch = train_gen.samples // train_gen.batch_size,\n","    validation_data = valid_gen,\n","    validation_steps = valid_gen.samples // valid_gen.batch_size,\n","    epochs = 20,\n","    callbacks=[checkpoint]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xCUoKeI5HLMu"},"outputs":[],"source":["# Vẽ đồ thị loss, accuracy của traning set và validation set\n","fig = plt.figure()\n","numOfEpoch = 10\n","plt.plot(np.arange(0, numOfEpoch), H.history['loss'], label='training loss')\n","plt.plot(np.arange(0, numOfEpoch), H.history['val_loss'], label='validation loss')\n","plt.plot(np.arange(0, numOfEpoch), H.history['accuracy'], label='accuracy') # sử dụng từ khóa accuracy thay vì acc\n","plt.plot(np.arange(0, numOfEpoch), H.history['val_accuracy'], label='validation accuracy') # sử dụng từ khóa val_accuracy thay vì val_acc\n","plt.title('Accuracy and Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss|Accuracy')\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bynfnBlcHLMw"},"outputs":[],"source":["from keras.models import load_model\n","model = load_model('models/model-ResNet50-009.keras')\n","\n","score = model.evaluate(X_test, y_test, verbose=1)\n","print(score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"leNIVyuOHLM1"},"outputs":[],"source":["# Đánh giá model\n","preds = model.predict(X_test) # DỰ ĐOÁN VÀ ĐÁNH GIÁ\n","preds = np.argmax(preds, axis=1)\n","print(classification_report(y_test, preds))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttKmAVfUHLM4"},"outputs":[],"source":["# 10. Dự đoán ảnh\n","plt.imshow(X_test[0])\n","plt.axis('off')\n","plt.show()\n","\n","y_predict = model.predict(np.expand_dims(X_test[0], axis=0))\n","print('Giá trị dự đoán: ', np.argmax(y_predict))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqfUxF13HLM6"},"outputs":[],"source":["# Tạo ma trận nhầm lẫn\n","cm = confusion_matrix(y_test, preds)\n","\n","# Chuyển nhãn số thành tên\n","label_names = le.inverse_transform(np.unique(y_test))\n","label_names = [label.split('/')[-1] for label in label_names]\n","# Sắp xếp lại ma trận nhầm lẫn\n","sorted_cm = cm[np.argsort(label_names)][:, np.argsort(label_names)]\n","\n","# Tạo dataframe từ ma trận nhầm lẫn đã sắp xếp lại\n","df_cm = pd.DataFrame(sorted_cm, index=label_names, columns=label_names)\n","\n","# Vẽ ma trận nhầm lẫn\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(df_cm, annot=True, cmap='Blues', fmt='g')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.show()\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
