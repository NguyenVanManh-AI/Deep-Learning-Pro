{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNets Flower Classification Implement : resnet18 , resnet34 , resnet50 , resnet101 , resnet152"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LƯU Ý : Với Model ResNet này lên đến ~59tr tham số . Rất khó trong việc traning . Mặc khác nếu cho batch size và epoch thấp thì độ chính xác lại không cao . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/content/drive/MyDrive/DeepLearning/Research/Flower_Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = '/content/drive/MyDrive/DeepLearning/Research/Flower_Classification/Dataset/imagelabels.mat' # cách 1\n",
    "# file_path = './Dataset/imagelabels.mat' # cách 2 , vì ta đã có chỉ định nơi làm việc ở đầu tiên là : os.chdir('/content/drive/MyDrive/DeepLearning/Research/Flower_Classification')\n",
    "# !unzip cũng nên dùng cách ngày cho ngắn gọn\n",
    "# !unzip ./Dataset/Dataset_102flower_TOP15.zip -d ./Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip /content/drive/MyDrive/DeepLearning/Research/Flower_Classification/Dataset/Dataset_102flower_TOP15.zip -d /content/drive/MyDrive/DeepLearning/Research/Flower_Classification/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imutils # cách fix trên kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, concatenate, BatchNormalization, Dropout, Activation, MaxPooling2D, GlobalAveragePooling2D, Dense, Add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from imutils import paths\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Label of Flower : Load file .mat \n",
    "- Trong folder 102flowers các file ảnh được sắp xếp theo đúng thứ tự với label trong file .mat \n",
    "- Label của 102 loài hoa là bằng số từ 1 đến 102 , thật ra nó không ảnh hưởng gì cả , text hay số đều cũng chỉ là một label mà thôi \n",
    "- Chứa 8189 ảnh gồm 102 loài hoa \n",
    "- Ta có thể rename lại toàn bộ ảnh bằng các thêm label vào phía trước "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể huấn luyện model này bằng dữ liệu 8189 ảnh gồm 102 loài hoa , nó sẽ học để nhận diện đặc điểm các loài hoa , sau khi thu được model này ta sẽ dùng nó để : Transfer learning : feature extractor dùng cho bài toán số nhãn thay đổi . Giả sử ta thêm loài hoa thứ 103 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoặc ta có thể sử dụng dữ liệu 8189 gồm 102 loài hoa này Transfer learning : Fine tuning lại một model nào đó , sau đó dùng nó để Transfer learning : Featre Extractor cũng để dùng cho bài toán số nhãn thay đổi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traning bằng TOP 15 loài hoa có số lượng mẫu nhiều nhất "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = '/content/drive/MyDrive/DeepLearning/Research/Flower_Classification/Dataset/imagelabels.mat' # cách 1\n",
    "file_path = './Dataset/imagelabels.mat' # cách 2 , vì ta đã có chỉ định nơi làm việc ở đầu tiên là : os.chdir('/content/drive/MyDrive/DeepLearning/Research/Flower_Classification')\n",
    "mat_data = loadmat(file_path)\n",
    "labels = mat_data['labels']\n",
    "unique_labels, counts = np.unique(labels[0], return_counts=True)\n",
    "sorted_indices = np.argsort(counts)[::-1]\n",
    "top_labels = unique_labels[sorted_indices][:15]\n",
    "top_counts = counts[sorted_indices][:15]\n",
    "i = 1\n",
    "total = 0\n",
    "for label, count in zip(top_labels, top_counts):\n",
    "    print(f\"{i}. {label}: {count}\")\n",
    "    total += count\n",
    "    i += 1\n",
    "print('Have',total,'img of 15 label')\n",
    "labels = top_labels\n",
    "unique_labels = np.unique(labels).astype(str)\n",
    "new_unique_labels = []\n",
    "for label in unique_labels:\n",
    "    new_label = label + 'label'\n",
    "    new_unique_labels.append(new_label)\n",
    "new_unique_labels = np.array(new_unique_labels)\n",
    "\n",
    "label_names = new_unique_labels\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiền xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './Dataset/Dataset_102flower_TOP15'\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "val_dir = os.path.join(root_dir, 'val')\n",
    "test_dir = os.path.join(root_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224 , 224)\n",
    "batch_size = 2\n",
    "img_shape = (img_size[0] , img_size[1] , 3)\n",
    "\n",
    "# tr_gen = ImageDataGenerator(rotation_range=20,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.2,\n",
    "                                #    zoom_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode='nearest')\n",
    "\n",
    "tr_gen = ImageDataGenerator()\n",
    "ts_gen = ImageDataGenerator()\n",
    "\n",
    "train_gen = tr_gen.flow_from_directory(train_dir , target_size = img_size , class_mode = 'categorical' ,\n",
    "                                       color_mode = 'rgb' , shuffle = True , batch_size = batch_size)\n",
    "\n",
    "valid_gen = ts_gen.flow_from_directory(val_dir , target_size = img_size , class_mode = 'categorical' ,\n",
    "                                       color_mode = 'rgb' , shuffle = True , batch_size = batch_size)\n",
    "\n",
    "test_gen = ts_gen.flow_from_directory(test_dir , target_size = img_size , class_mode = 'categorical' ,\n",
    "                                       color_mode = 'rgb' , shuffle = False , batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Sample From Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_dict = train_gen.class_indices\n",
    "classes = list(g_dict.keys())\n",
    "images, labels = next(train_gen)\n",
    "num_samples = len(images)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i in range(min(16, num_samples)):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    image = images[i] / 255\n",
    "    plt.imshow(image)\n",
    "    class_index = np.argmax(labels[i]) # Lấy chỉ mục của lớp có xác suất cao nhất\n",
    "    class_name = classes[class_index]\n",
    "    plt.title(class_name, color='blue', fontsize=12)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xây dựng Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import sys\n",
    "\n",
    "class BasicBlock(tf.keras.Model):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, strides=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(out_channels, kernel_size=3, strides=strides, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv2 = layers.Conv2D(out_channels, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "\n",
    "        if strides != 1 or in_channels != self.expansion*out_channels:\n",
    "            self.shortcut = tf.keras.Sequential([\n",
    "                layers.Conv2D(self.expansion*out_channels, kernel_size=1, strides=strides, use_bias=False),\n",
    "                layers.BatchNormalization()\n",
    "            ])\n",
    "        else:\n",
    "            self.shortcut = lambda x: x\n",
    "\n",
    "    def call(self, x):\n",
    "        out = tf.keras.activations.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = layers.add([self.shortcut(x), out])\n",
    "        out = tf.keras.activations.relu(out)\n",
    "        return out\n",
    "\n",
    "class BottleNeck(tf.keras.Model):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, strides=1):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(out_channels, kernel_size=1, use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv2 = layers.Conv2D(out_channels, kernel_size=3, strides=strides, padding='same', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.conv3 = layers.Conv2D(self.expansion*out_channels, kernel_size=1, use_bias=False)\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "\n",
    "        if strides != 1 or in_channels != self.expansion*out_channels:\n",
    "            self.shortcut = tf.keras.Sequential([\n",
    "                layers.Conv2D(self.expansion*out_channels, kernel_size=1, strides=strides, use_bias=False),\n",
    "                layers.BatchNormalization()\n",
    "            ])\n",
    "        else:\n",
    "            self.shortcut = lambda x: x\n",
    "\n",
    "    def call(self, x):\n",
    "        out = tf.keras.activations.relu(self.bn1(self.conv1(x)))\n",
    "        out = tf.keras.activations.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = layers.add([self.shortcut(x), out])\n",
    "        out = tf.keras.activations.relu(out)\n",
    "        return out\n",
    "\n",
    "class BuildResNet(tf.keras.Model):\n",
    "    def __init__(self, block, num_blocks, num_classes):\n",
    "        super(BuildResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], strides=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], strides=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], strides=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], strides=2)\n",
    "        self.avg_pool2d = layers.AveragePooling2D(pool_size=4)\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        out = tf.keras.activations.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avg_pool2d(out)\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, strides):\n",
    "        stride = [strides] + [1]*(num_blocks-1)\n",
    "        layer = []\n",
    "        for s in stride:\n",
    "            layer += [block(self.in_channels, out_channels, s)]\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return tf.keras.Sequential(layer)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "          'block': self.block,\n",
    "          'num_blocks': self.num_blocks,\n",
    "          'num_classes': self.num_classes\n",
    "        }\n",
    "        return config\n",
    "\n",
    "def ResNet(model_type, num_classes):\n",
    "    if model_type == 'resnet18':\n",
    "        return BuildResNet(BasicBlock, [2, 2, 2, 2], num_classes)\n",
    "    elif model_type == 'resnet34':\n",
    "        return BuildResNet(BasicBlock, [3, 4, 6, 3], num_classes)\n",
    "    elif model_type == 'resnet50':\n",
    "        return BuildResNet(BottleNeck, [3, 4, 6, 3], num_classes)\n",
    "    elif model_type == 'resnet101':\n",
    "        return BuildResNet(BottleNeck, [3, 4, 23, 3], num_classes)\n",
    "    elif model_type == 'resnet152':\n",
    "        return BuildResNet(BottleNeck, [3, 8, 36, 3], num_classes)\n",
    "    else:\n",
    "        sys.exit(ValueError(\"{:s} is currently not supported.\".format(model_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNetModel = ResNet(model_type = 'resnet152', num_classes = len(label_names)) # 15 nhãn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNetModel.build((1, 224, 224, 3))\n",
    "ResNetModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nếu chạy đoạn code load model ở trên google colab thì nó hiện ra được kiến trúc , còn dưới này nó không hiện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo đối tượng optimizer  # SGD\n",
    "# optimizer = tf.keras.optimizers.Adam()\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "# optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.01)\n",
    "# optimizer = tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95)\n",
    "# optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# optimizer = tf.keras.optimizers.Ftrl(learning_rate=0.001, learning_rate_power=-0.5, initial_accumulator_value=0.1, l1_regularization_strength=0.0, l2_regularization_strength=0.0)\n",
    "# optimizer = tf.keras.optimizers.Adamax(learning_rate=0.002, beta_1=0.9, beta_2=0.999)\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Thiết lập ModelCheckpoint\n",
    "save_best_only = True\n",
    "checkpoint = ModelCheckpoint('models/Resnet152-model-epoch-{epoch:03d}.keras',\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=save_best_only,\n",
    "                             mode='auto')\n",
    "\n",
    "# Xây dựng quy trình huấn luyện\n",
    "ResNetModel.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Huấn luyện mô hình với dữ liệu đã chuẩn bị\n",
    "H = ResNetModel.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch = train_gen.samples // train_gen.batch_size,\n",
    "    validation_data = valid_gen,\n",
    "    validation_steps = valid_gen.samples // valid_gen.batch_size,\n",
    "    epochs = 3,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = H.history['accuracy']\n",
    "train_loss = H.history['loss']\n",
    "\n",
    "val_acc = H.history['val_accuracy']\n",
    "val_loss = H.history['val_loss']\n",
    "\n",
    "index_loss = np.argmin(val_loss)\n",
    "index_acc = np.argmax(val_acc)\n",
    "\n",
    "val_lowest = val_loss[index_loss]\n",
    "val_highest = val_acc[index_acc]\n",
    "\n",
    "Epochs = [i+1 for i in range(len(train_acc))]\n",
    "\n",
    "loss_label = f'Best Epoch = {str(index_loss + 1)}'\n",
    "acc_label = f'Best Epoch = {str(index_acc + 1)}'\n",
    "\n",
    "plt.figure(figsize= (20,8))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(Epochs , train_loss , 'r', label = 'Training Loss')\n",
    "plt.plot(Epochs , val_loss , 'g' , label = 'Validation Loss')\n",
    "plt.scatter(index_loss +1 , val_lowest , s = 150 , c = 'blue' , label = loss_label)\n",
    "plt.title('Training vs Validation (loss)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(Epochs , train_acc , 'r', label= 'Training Accuracy')\n",
    "plt.plot(Epochs , val_acc , 'g' , label = 'Validation Accuracy')\n",
    "plt.scatter(index_acc + 1 , val_highest , s= 150 , c = 'blue' , label= acc_label)\n",
    "plt.title('Training vs Validation (Accuracy)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = ResNetModel.evaluate(train_gen , steps= 32 , verbose = 1)\n",
    "val_score = ResNetModel.evaluate(valid_gen , steps = 32 , verbose = 1)\n",
    "test_score = ResNetModel.evaluate(test_gen , steps = 32 , verbose = 1)\n",
    "\n",
    "print(f'Train loss = {train_score[0] }')\n",
    "print(f'Train Accuracy = {train_score[1]}')\n",
    "print(f'Validation loss = {val_score[0]}')\n",
    "print(f'Validation Accuracy = {val_score[1]}')\n",
    "print(f'Test loss = {test_score[0]}')\n",
    "print(f'Test Accuracy = {test_score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Dự đoán\n",
    "preds = ResNetModel.predict(test_gen)\n",
    "preds = np.argmax(preds, axis=1)\n",
    "\n",
    "# Lấy nhãn thật\n",
    "true_labels = test_gen.classes\n",
    "\n",
    "# Tính các chỉ số\n",
    "report = classification_report(true_labels, preds, output_dict=True)\n",
    "\n",
    "# In chỉ số f1, precision, recall\n",
    "print(\"F1:\", report['weighted avg']['f1-score'])\n",
    "print(\"Precision:\", report['weighted avg']['precision'])\n",
    "print(\"Recall:\", report['weighted avg']['recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(true_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "from tensorflow.keras.models import load_model\n",
    "best_model_ConvNeXt = load_model('models/ConvNeXt_model-022.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lấy mẫu ra từ test_gen để dự đoán "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy một mẫu ngẫu nhiên từ test_gen\n",
    "random_index = random.randint(0, len(test_gen) - 1)  \n",
    "batch = test_gen[random_index] \n",
    "\n",
    "# In hình ảnh \n",
    "random_img = random.randint(0, len(batch) - 1)  \n",
    "img = batch[0][random_img]\n",
    "img = img.astype(float)/255\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# In ra nhãn \n",
    "label = batch[1][random_img]\n",
    "print('label encoder', batch[1][0])\n",
    "print('Nhãn ban đầu :', classes[np.argmax(label)])\n",
    "\n",
    "\n",
    "# Chuyển đổi thành 4D tensor\n",
    "img = batch[0][random_img]\n",
    "print(img.shape)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "print(img.shape)\n",
    "# Dự đoán\n",
    "pred = best_model_ConvNeXt.predict(img)\n",
    "print('Dự đoán:', classes[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lấy mẫu ảnh ra từ folder test để dự đoán "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy một file ảnh ngẫy nhiên trong folder test \n",
    "test_folder = 'Dataset/Dataset_Alzheimer_6400/test'\n",
    "subfolders = [os.path.join(test_folder, subfolder) for subfolder in os.listdir(test_folder) if os.path.isdir(os.path.join(test_folder, subfolder))]\n",
    "random_subfolder = random.choice(subfolders)\n",
    "subfolder_images = os.listdir(random_subfolder)\n",
    "random_image_name = random.choice(subfolder_images)\n",
    "random_image_path = os.path.join(random_subfolder, random_image_name)\n",
    "\n",
    "# In ra tên của ảnh được chọn\n",
    "print(\"Tên file ảnh được chọn:\", random_image_name)\n",
    "\n",
    "# Load ảnh và chuyển thành tensor\n",
    "img = load_img(random_image_path)\n",
    "img = img.resize((32, 32))  # Resize ảnh về kích thước (32, 32)\n",
    "img_array = img_to_array(img)\n",
    "img_tensor = tf.expand_dims(img_array, axis=0)  # Thêm chiều batch\n",
    "# print(img_tensor.shape)\n",
    "# print(img_tensor)\n",
    "\n",
    "# Load mô hình đã được lưu trữ\n",
    "# Dự đoán nhãn của ảnh\n",
    "predictions = best_model_ConvNeXt.predict(img_tensor)\n",
    "\n",
    "# In ra nhãn dự đoán\n",
    "print('Dự đoán:', classes[np.argmax(predictions)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính confusion matrix\n",
    "conf_mat = confusion_matrix(true_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assume you already have the confusion matrix (cm), sorted confusion matrix (sorted_cm), DataFrame (df_cm),\n",
    "# true labels (true_labels), predicted labels (preds), and classes defined\n",
    "\n",
    "# Tạo ma trận nhầm lẫn\n",
    "cm = confusion_matrix(true_labels, preds)\n",
    "\n",
    "# Sắp xếp lại ma trận nhầm lẫn\n",
    "sorted_cm = cm[np.argsort(classes)][:, np.argsort(classes)]\n",
    "\n",
    "# Tạo dataframe từ ma trận nhầm lẫn đã sắp xếp lại\n",
    "df_cm = pd.DataFrame(sorted_cm, index=classes, columns=classes)\n",
    "\n",
    "# Set font size\n",
    "font_size = 10\n",
    "\n",
    "# Vẽ ma trận nhầm lẫn với font size đã điều chỉnh\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_cm, annot=True, cmap='Blues', fmt='g', annot_kws={\"size\": font_size})\n",
    "plt.xlabel('Predicted labels', fontsize=font_size)\n",
    "plt.ylabel('True labels', fontsize=font_size)\n",
    "plt.xticks(fontsize=font_size)\n",
    "plt.yticks(fontsize=font_size)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
